{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data for classification\n",
    "\n",
    "**Author:** Manuela Linke & Tobias Meßmer, HTWG Konstanz \n",
    "\n",
    "**Date:** 15.03.2024 \n",
    "\n",
    "**Summary:** This Script reads in simulated grid data and converts the results into standardized, one-hot-encoded classes. The data gets split into train (70%), test (15%) and validation data (15%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd \n",
    "import os\n",
    "import math\n",
    "from collections import Counter\n",
    "import pandapower as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select modus and define seed for random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which data should be considered as input data: load, volt or loadANDvolt\n",
    "modus = 'volt'\n",
    "\n",
    "# Set seed for random state\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define path\n",
    "net = pp.from_pickle(\"cossmic_grid.p\")\n",
    "input_path = os.path.join('data', 'preprocessed', '')\n",
    "date = '2024-03-25_16-56-21' # Replace this with the actual date in format yyyy-mm-dd_hh-mm-ss'\n",
    "\n",
    "#Load data\n",
    "X_load = np.load(input_path + date + \"_Load_distribution.npy\")\n",
    "X_volt = np.load(input_path + date + \"_voltage_distribution.npy\")\n",
    "y_changes = np.load(input_path + date + \"__min_chg_from_base.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52558, 11)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_load.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.63e-01,  1.60e-03,  2.56e-01,  6.70e-03,  2.80e-04,  5.20e-03,\n",
       "         5.40e-04, -3.70e-03, -3.50e-03, -2.00e-02,  1.92e-01],\n",
       "       [ 1.63e-01,  1.12e-02,  7.68e-01,  6.70e-03,  2.80e-04,  1.56e-02,\n",
       "         1.74e-02,  3.20e-04,  3.60e-04,  2.70e-03,  1.92e-01],\n",
       "       [ 4.89e-01,  1.12e-02,  7.97e-02,  2.01e-02,  2.80e-04,  5.20e-03,\n",
       "         5.80e-03,  3.20e-04,  3.50e-03,  2.70e-03,  5.76e-01],\n",
       "       [ 4.89e-01,  1.12e-02,  2.56e-01,  2.01e-02,  2.80e-04,  4.40e-04,\n",
       "         1.74e-02,  3.70e-03,  3.60e-04,  2.00e-02,  1.92e-01],\n",
       "       [ 1.63e-01, -1.12e-02,  2.56e-01,  5.80e-04,  8.10e-03, -5.20e-03,\n",
       "        -5.80e-03,  3.70e-03,  3.50e-03,  2.00e-02,  1.92e-01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_load[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets take a look at the solutions for the 52558 Problems:\n",
      "Not solvable (0) / Solvable (1) Problems: Counter({0: 34720, 1: 17838})\n",
      "Used steps for Transformer station 1: Counter({-1: 37176, 0: 14283, -2: 1099})\n",
      "Used steps for Transformer station 1: Counter({-1: 29385, -2: 18247, 0: 4926})\n"
     ]
    }
   ],
   "source": [
    "# set X-data to variable X_data (X_load, X_volt or X_load and X_volt)\n",
    "if modus == 'load':\n",
    "    X_data = X_load\n",
    "    \n",
    "if modus == 'volt':\n",
    "    X_data = X_volt\n",
    "    \n",
    "if modus == 'loadANDvolt':\n",
    "    X_data = np.append(X_load, X_volt, axis=1)\n",
    "    \n",
    "# set y-data to variable y_data_matrix (changes)\n",
    "y_data_matrix = y_changes\n",
    "\n",
    "print(\"Lets take a look at the solutions for the \" + str(len(X_data)) + \" Problems:\")\n",
    "\n",
    "indikator = Counter(y_data_matrix[:,-1])\n",
    "trafo2 = Counter(y_data_matrix[:,-2])\n",
    "trafo1 = Counter(y_data_matrix[:,-3])\n",
    "\n",
    "print(\"Not solvable (0) / Solvable (1) Problems: \" + str(indikator))\n",
    "print(\"Used steps for Transformer station 1: \" + str(trafo1))\n",
    "print(\"Used steps for Transformer station 1: \" + str(trafo2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare y-data\n",
    "### One hot encoding of the tranformer tap positions and converting y-data to a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_switches = len(net.switch[net.switch.et == 'l'])\n",
    "\n",
    "# number of transformer stations\n",
    "num_trafos = len(net.trafo)\n",
    "\n",
    "# defining the colums belongig to the transformer stations\n",
    "trafo_columns_start = num_switches\n",
    "trafo_columns_end = num_switches + num_trafos\n",
    "trafo_columns_indices = list(range(trafo_columns_start, trafo_columns_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tap_pos_ranges = [range(row['tap_min'], row['tap_max']+1) for index, row in net.trafo.iterrows()]\n",
    "categories = [list(tap_range) for tap_range in tap_pos_ranges]\n",
    "\n",
    "# Initialisation of the OneHotEncoder\n",
    "encoder = OneHotEncoder(categories=categories)\n",
    "\n",
    "# Encoding the transformer tap changer position columns to one hot format\n",
    "encoded_columns = encoder.fit_transform(y_data_matrix[:, trafo_columns_indices]).toarray()\n",
    "\n",
    "# Remove the old columns and add the encoded columns\n",
    "y_data_matrix_extended = np.hstack((y_data_matrix[:, :trafo_columns_start], encoded_columns, y_data_matrix[:, trafo_columns_end:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Boolean values to integers and calculating decimal values\n",
    "y_data = np.dot(y_data_matrix_extended.astype(int), 2**np.arange(y_data_matrix_extended.shape[1])[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for Classification: Changing the large decimal values to smaller numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of y_data for training, validation and test: 52558\n",
      "Number of occuring results: 34\n"
     ]
    }
   ],
   "source": [
    "# Find unique values in y_data and assign them to a new index\n",
    "unique_values, y_data_result = np.unique(y_data, return_inverse=True)\n",
    "print('Amount of y_data for training, validation and test:', len(y_data_result))\n",
    "print('Number of occuring results:', max(y_data_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shuffle and split data to trainings, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Große des Datensatzes: 36790 (Training) + 7884 (Validation) + 7884 (Test) = 52558\n"
     ]
    }
   ],
   "source": [
    "#shuffle and split \n",
    "X_train, X_tobesplittet, y_train, y_tobesplittet = train_test_split(X_data, y_data_result, test_size=0.3, random_state=seed)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_tobesplittet, y_tobesplittet, test_size=0.5, random_state=seed)\n",
    "print('Große des Datensatzes: ' + str(len(X_train)) + ' (Training) + ' + str(len(X_val)) + ' (Validation) + ' + str(len(X_test)) + ' (Test) = ' + str(len(X_train)+len(X_val)+len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize X-data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Using StandardScaler \n",
    "sc = StandardScaler()\n",
    "\n",
    "# to be tested if necessary .. \n",
    "if modus == 'loadANDvolt':\n",
    "    # Adapt the scaler to the training data and its transformation\n",
    "    X_train_std_ = sc.fit_transform(X_train[:,:X_load.shape[1]])\n",
    "    # Transformation of the test data with the same parameters as the training data\n",
    "    X_val_std_ = sc.transform(X_val[:,:X_load.shape[1]])\n",
    "    X_test_std_ = sc.transform(X_test[:,:X_load.shape[1]])\n",
    "    # appending voltage values without standardisation\n",
    "    X_train_std = np.append(X_train_std_, X_train[:,X_load.shape[1]:],1)\n",
    "    X_val_std = np.append(X_val_std_, X_val[:,X_load.shape[1]:],1)\n",
    "    X_test_std = np.append(X_test_std_, X_test[:,X_load.shape[1]:],1)\n",
    "\n",
    "else:\n",
    "    # Adapt the scaler to the training data and its transformation\n",
    "    X_train_std = sc.fit_transform(X_train)\n",
    "    # Transformation of the test data with the same parameters as the training data\n",
    "    X_val_std = sc.transform(X_val)\n",
    "    X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify y-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning y data into one hot encoding\n",
    "Y_train = to_categorical(y_train, max(y_data_result) + 1)\n",
    "Y_val = to_categorical(y_val, max(y_data_result) + 1)\n",
    "Y_test = to_categorical(y_test, max(y_data_result) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path 'data\\prepared\\' already exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the path you want to ensure exists\n",
    "savePath = os.path.join('data', 'prepared', '')\n",
    "\n",
    "# Check if the path exists\n",
    "if not os.path.exists(savePath):\n",
    "    # If it doesn't exist, create it\n",
    "    os.makedirs(savePath)\n",
    "    print(f\"Path '{savePath}' was created.\")\n",
    "else:\n",
    "    print(f\"Path '{savePath}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(savePath + date + \"_X_train_std_\" + modus + \".npy\", X_train_std)\n",
    "np.save(savePath + date + \"_X_val_std_\" + modus + \".npy\", X_val_std)\n",
    "np.save(savePath + date + \"_X_test_std_\" + modus + \".npy\", X_test_std)\n",
    "\n",
    "np.save(savePath + date + \"_Y_train.npy\", Y_train) \n",
    "np.save(savePath + date + \"_Y_val.npy\", Y_val)\n",
    "np.save(savePath + date + \"_Y_test.npy\", Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When making sure to use the rigth columns in the grid, its better to have the names of the loads stored. Feather-format is right for this:\n",
    "# converting to df to store in feather format\n",
    "colum_names = net.load.name\n",
    "if modus != 'loadANDvolt':\n",
    "    X_train_std_df = pd.DataFrame(X_train_std, columns = colum_names)\n",
    "    X_train_std_df.to_feather(savePath + date + \"_X_train_std_\" + modus + \".feather\")\n",
    "    X_val_std_df = pd.DataFrame(X_val_std, columns = colum_names)\n",
    "    X_val_std_df.to_feather(savePath + date + \"_X_val_std_\" + modus + \".feather\")\n",
    "    X_test_std_df = pd.DataFrame(X_test_std, columns = colum_names)\n",
    "    X_test_std_df.to_feather(savePath + date + \"_X_test_std_\" + modus + \".feather\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

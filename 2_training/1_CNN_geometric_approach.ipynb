{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f633dd8e-8a17-4b23-9c1e-8bd9ba1a5872",
   "metadata": {},
   "source": [
    "# CNN geometric approach\n",
    "\n",
    "**Author:** Manuela Linke, HTWG Konstanz \n",
    "\n",
    "**Date:** 15.03.2024 \n",
    "\n",
    "**Summary:** This Script reshapes the input data for CNN training into different pictures, optimizes the hyperparameters and can be used to evaluate the best model with the N-Best Approach.\n",
    "\n",
    "**License:** Copyright 2024 Manuela Linke\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478b6f90-d6a7-4e72-b094-dc5af3e14ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time as t\n",
    "import datetime as dt\n",
    "import pandapower as pp\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, AveragePooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger, TensorBoard\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from tensorflow.keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff7b6eb-74d2-4e66-9b50-2707f10b8ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#region settings\n",
    "print('TensorFlow version:', tf.__version__)\n",
    "#print('GPU available:', tf.test.is_gpu_available())\n",
    "print('Built with CUDA:', tf.test.is_built_with_cuda())\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdc4a6e-e1e8-42ea-83db-bdfcb74108f5",
   "metadata": {},
   "source": [
    "## Parameters to be set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8d7fcb-5d35-4176-8cad-b757a5a71185",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2024-03-22_13-06-27' # Replace this with the actual date in format yyyy-mm-dd_hh-mm-ss'\n",
    "\n",
    "save_model = True    # save keras model as HDF5 file\n",
    "log_training = True  # log training to display later in tensorboard\n",
    "version = 'geom_V5' # geom_V2, geom_V3, geom_V4, geom_V5, phys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1557e90d-6efa-4d33-a26a-08f3d5654375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths\n",
    "path_to_grid = os.path.join('..','1_training data generation', 'cossmic_grid.p')\n",
    "net = pp.from_pickle(path_to_grid)\n",
    "\n",
    "input_path = os.path.join('..', '1_training data generation', 'data', 'prepared', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a62f2a3-2a3f-4d4e-85ab-2b7d97d13362",
   "metadata": {},
   "source": [
    "## Define output folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b960c9-6fdd-45ec-bc87-73b1226f658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_models = os.path.join('CNN_models', date, version)\n",
    "folder_reports = os.path.join('Reports', date, version)\n",
    "log_dir = os.path.join('logs', 'fit', date, version)\n",
    "\n",
    "if not os.path.exists(folder_reports):\n",
    "    os.makedirs(folder_reports)\n",
    "    \n",
    "if not os.path.exists(folder_models):\n",
    "    os.makedirs(folder_models)\n",
    "\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e48cec1-14f3-4ac8-92b4-563d115899fc",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c6b61e-01b7-4581-81e5-d06e7d8c5056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input_pic_V1(load, pic_dim1, pic_dim2):\n",
    "    # Hardcoded, the automatic generation of this picture is not possible\n",
    "    # load: training data \n",
    "    pic = np.zeros((len(load), pic_dim1, pic_dim2))  # dimension of 7X5 for this arrangement\n",
    "    for i in range(len(load)):\n",
    "        pic[i,3,2] = load[i,0]  # Ind1\n",
    "        pic[i,2,1] = load[i,1]  # Ind2\n",
    "        pic[i,3,0] = load[i,2]  # Ind3\n",
    "        pic[i,2,4] = load[i,3]  # Residential1\n",
    "        pic[i,3,4] = load[i,4]  # Residential2\n",
    "        pic[i,4,4] = load[i,5]  # Residential3\n",
    "        pic[i,3,6] = load[i,6]  # Residential4\n",
    "        pic[i,2,6] = load[i,7]  # Residential5\n",
    "        pic[i,0,5] = load[i,8]  # Residential6\n",
    "        pic[i,1,4] = load[i,9]  # School1\n",
    "        pic[i,1,6] = load[i,10]  # School2\n",
    "    return pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39496138-7230-462d-bc31-743795d4a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input_pic_V2(load, pic_dim1, pic_dim2):\n",
    "    # Hardcoded, the automatic generation of this picture is not possible\n",
    "    # load: training data \n",
    "    pic = np.zeros((len(load), pic_dim1, pic_dim2))  # dimension of 7X5 for this arrangement\n",
    "    for i in range(len(load)):\n",
    "        pic[i,3,3] = load[i,0]  # Ind1\n",
    "        pic[i,3,4] = load[i,1]  # Ind2\n",
    "        pic[i,4,3] = load[i,2]  # Ind3\n",
    "        pic[i,2,0] = load[i,3]  # Residential1\n",
    "        pic[i,3,0] = load[i,4]  # Residential2\n",
    "        pic[i,4,0] = load[i,5]  # Residential3\n",
    "        pic[i,0,3] = load[i,6]  # Residential4\n",
    "        pic[i,0,2] = load[i,7]  # Residential5\n",
    "        pic[i,0,0] = load[i,8]  # Residential6\n",
    "        pic[i,0,1] = load[i,9]  # School1\n",
    "        pic[i,3,4] = load[i,10]  # School2\n",
    "    return pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d662ac7c-1ae0-4a80-8c1a-c1569d045988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input_pic_V3(load, pic_dim1, pic_dim2):\n",
    "    # Hardcoded, the automatic generation of this picture is not possible\n",
    "    # load: training data \n",
    "    pic = np.zeros((len(load), pic_dim1, pic_dim2))  # dimension of 7X5 for this arrangement\n",
    "    for i in range(len(load)):\n",
    "        pic[i,3,0] = load[i,0]  # Ind1\n",
    "        pic[i,4,0] = load[i,1]  # Ind2\n",
    "        pic[i,5,0] = load[i,2]  # Ind3\n",
    "        pic[i,2,1] = load[i,3]  # Residential1\n",
    "        pic[i,1,1] = load[i,4]  # Residential2\n",
    "        pic[i,0,1] = load[i,5]  # Residential3\n",
    "        pic[i,7,1] = load[i,6]  # Residential4\n",
    "        pic[i,6,1] = load[i,7]  # Residential5\n",
    "        pic[i,4,1] = load[i,8]  # Residential6\n",
    "        pic[i,3,1] = load[i,9]  # School1\n",
    "        pic[i,5,1] = load[i,10]  # School2\n",
    "    return pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c1db00-178a-4c9f-8727-9ea00b6a9715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input_pic_V4(load, pic_dim1, pic_dim2):\n",
    "    # Hardcoded, the automatic generation of this picture is not possible\n",
    "    # load: training data \n",
    "    pic = np.zeros((len(load), pic_dim1, pic_dim2))  # dimension of 7X5 for this arrangement\n",
    "    for i in range(len(load)):\n",
    "        pic[i,0] = load[i,0]  # Ind1\n",
    "        pic[i,1] = load[i,1]  # Ind2\n",
    "        pic[i,2] = load[i,2]  # Ind3\n",
    "        pic[i,5] = load[i,3]  # Residential1\n",
    "        pic[i,4] = load[i,4]  # Residential2\n",
    "        pic[i,3] = load[i,5]  # Residential3\n",
    "        pic[i,10] = load[i,6]  # Residential4\n",
    "        pic[i,9] = load[i,7]  # Residential5\n",
    "        pic[i,7] = load[i,8]  # Residential6\n",
    "        pic[i,6] = load[i,9]  # School1\n",
    "        pic[i,8] = load[i,10]  # School2\n",
    "    return pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1c026e-45d6-40fd-af54-d1be6becd414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input_pic_V5(load, pic_dim1, pic_dim2):\n",
    "    # Hardcoded, the automatic generation of this picture is not possible\n",
    "    # load: training data \n",
    "    pic = np.zeros((len(load), pic_dim1, pic_dim2))  # dimension of 7X5 for this arrangement\n",
    "    for i in range(len(load)):\n",
    "        pic[i,0] = load[i,0]  # Ind1\n",
    "        pic[i,1] = load[i,1]  # Ind2\n",
    "        pic[i,2] = load[i,2]  # Ind3\n",
    "        pic[i,6] = load[i,3]  # Residential1\n",
    "        pic[i,5] = load[i,4]  # Residential2\n",
    "        pic[i,4] = load[i,5]  # Residential3\n",
    "        pic[i,11] = load[i,6]  # Residential4\n",
    "        pic[i,10] = load[i,7]  # Residential5\n",
    "        pic[i,8] = load[i,8]  # Residential6\n",
    "        pic[i,7] = load[i,9]  # School1\n",
    "        pic[i,9] = load[i,10]  # School2\n",
    "    return pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9f8cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uncompiled_model(pic_dim1, pic_dim2, num_classes,\n",
    "                         numFilters_Layer1=32, numFilters_Layer2=64, numNeurons_Layer3=264,\n",
    "                         dropout_1=0.5, dropout_2=0.4):\n",
    "\n",
    "    \"\"\"\n",
    "        composes the Keras sequential model\n",
    "        INPUT:\n",
    "            **pic_dim1** - (int+) sets the x dimension of the input picture int\n",
    "            **pic_dim2** _ (int+)  sets the y dimension of the input picture int\n",
    "        OPTIONAL:\n",
    "            **numFilters_Layer1** - (int+,32)sets  Integer, the dimensionality of the output space of the first con_layer (i.e. the number of output filters in the convolution).\n",
    "            **numFilters_Layer2** - (int+,64)sets  Integer, the dimensionality of the output space of the second con_layer\n",
    "            **numNeurons_Layer3** - (int+,264) dimensionality of the first dense_layer output\n",
    "            **dropout_1** - (float, 0.5) between 0 and 1. Fraction of the input units to drop, for the first dropout\n",
    "            *+dropout_2** - (float, 0.4) between 0 and 1. Fraction of the input units to drop, for the second dropout\n",
    "\n",
    "        OUTPUT:\n",
    "            **model** - Keras sequential model of the parametrised CNN\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    numNeurons_Layer4 = num_classes  # outputLayer, depending on the number of possible solutions\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(numFilters_Layer1, 3, padding='valid', activation='relu', input_shape=(pic_dim1, pic_dim2)))\n",
    "    # model.add(AveragePooling1D(2))\n",
    "    # model.add(MaxPooling1D(2))\n",
    "    model.add(Conv1D(numFilters_Layer2, 3, activation='relu'))\n",
    "    #model.add(MaxPooling1D(2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(dropout_1))\n",
    "    model.add(Dense(numNeurons_Layer3, activation='relu'))\n",
    "    model.add(Dropout(dropout_2))\n",
    "    model.add(Dense(numNeurons_Layer4, activation='softmax'))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff63e42d-d411-41cb-a170-75cc17fc2877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model(optimizer, pic_dim1, pic_dim2, num_classes,\n",
    "                       numFilters_Layer1 = 32, numFilters_Layer2 = 64, numNeurons_Layer3 = 264,\n",
    "                       dropout_1 = 0.5 , dropout_2 = 0.4):\n",
    "    \"\"\"\n",
    "         compiles the sequential model und prints out the summary\n",
    "        INPUT:\n",
    "            **optimizer** - (string) sets common keras optimizer parsed as string\n",
    "            **pic_dim1** - (int+) sets the x dimension of the input picture int\n",
    "            **pic_dim2** _ (int+)  sets the y dimension of the input picture int\n",
    "        OPTIONAL:\n",
    "            **numFilters_Layer1** - (int+,32)sets  Integer, the dimensionality of the output space of the first con_layer (i.e. the number of output filters in the convolution).\n",
    "            **numFilters_Layer2** - (int+,64)sets  Integer, the dimensionality of the output space of the second con_layer\n",
    "            **numNeurons_Layer3** - (int+,264) dimensionality of the first dense_layer output\n",
    "            **dropout_1** - (float, 0.5) between 0 and 1. Fraction of the input units to drop, for the first dropout\n",
    "            *+dropout_2** - (float, 0.4) between 0 and 1. Fraction of the input units to drop, for the second dropout\n",
    "\n",
    "        OUTPUT:\n",
    "            **model** - Keras sequential model of the parametrised CNN\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    model = get_uncompiled_model(pic_dim1, pic_dim2, num_classes,\n",
    "                                 numFilters_Layer1, numFilters_Layer2, numNeurons_Layer3, \n",
    "                                 dropout_1, dropout_2)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e67a71a-61b2-43f6-8fe2-24bc34bc0c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_for_build_input_pic(\n",
    "        optimizer, num_classes, \n",
    "        folder_models, folder_reports,\n",
    "        pic_dim1, pic_dim2,\n",
    "        X_train, Y_train,\n",
    "        X_val, Y_val,\n",
    "        X_test, Y_test,\n",
    "        bs, ep, version, log_dir, save_model=True):\n",
    "    \"\"\"\n",
    "    executes the composing und compiling process of the network (Sequential model)\n",
    "    to train the resulting model on the given trainingdata.\n",
    "    The input data is generated using  build_input_pic or any other function that encodes the lines with the load.\n",
    "    It has thee dimension np.array(len(data),lines,3)\n",
    "    Afterwards the net gets testet and the model will be stored with a unequivocally name in the folder \"Daten CNN model\".\n",
    "\n",
    "\n",
    "        INPUT:\n",
    "            **X_train** -       (np.array(len(data),lines,3))holds the compose_3ChannelOneDV1 pics for the trainingdata\n",
    "            **Y_train** -   (np.array(len(data),lines))  holds an zero np.array for the number of trainingsamples\n",
    "            **X_val** -         (np.array(len(data),lines,3))compose_3ChannelOneDV1 pics for the validationdata\n",
    "            **Y_val** -     (np.array(len(data),lines))  holds an zero np.array for the number of validationsamples\n",
    "            **X_test** -        (np.array(len(data),lines,3))compose_3ChannelOneDV1 pics for the testdata\n",
    "            **Y_test** -    (np.array(len(data),lines))  holds an zero np.array for the number of testingsamples\n",
    "\n",
    "            needed for a inside the function called function\n",
    "            **optimizer** - (string) sets common keras optimizer parsed as string\n",
    "\n",
    "        OPTIONAL:\n",
    "            **bs** - (int,32) or None. Number of samples per gradient update. Do not specify the batch_size if your data is in the form of datasets, generators, or keras.utils.Sequence instances (since they generate batches).\n",
    "            **ep** - (int,30) Number of epochs to train the model. An epoch is an iteration over the entire x and y data provided. Note that in conjunction with initial_epoch, epochs is to be understood as \"final epoch\".\n",
    "\n",
    "            needed for a inside the function called function\n",
    "            **numFilters_Layer1** - (int+,128)sets  Integer, the dimensionality of the output space of the first con_layer (i.e. the number of output filters in the convolution).\n",
    "            **numFilters_Layer2** - (int+,128)sets  Integer, the dimensionality of the output space of the second con_layer\n",
    "            **numNeurons_Layer3** - (int+) dimensionality of the first dense_layer output\n",
    "            **dropout_1** - (float, 0.5) between 0 and 1. Fraction of the input units to drop, for the first dropout\n",
    "            *+dropout_2** - (float, 0.4) between 0 and 1. Fraction of the input units to drop, for the second dropout\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    print(\"Training the CNN..\")\n",
    "    model = get_compiled_model(optimizer = optimizer, pic_dim1 = pic_dim1, pic_dim2 = pic_dim2, num_classes = num_classes)  # num_classes = number of possible solutions\n",
    "   \n",
    "    #model.summary()\n",
    "    #####\n",
    "\n",
    "    t00 = t.time()\n",
    "\n",
    "    callbacks = [\n",
    "        CSVLogger(os.path.join(log_dir, 'bs_' + str(bs) + '-ep_' + str(ep) + '-op_' + optimizer + \"_\" + version + '_logging.csv'))  # training.log\n",
    "    ]\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    '''    EarlyStopping(\n",
    "            # Stop training when `val_loss` is no longer improving\n",
    "            monitor=\"val_loss\",\n",
    "            # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "            min_delta=1e-2,\n",
    "            # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
    "            patience=2,\n",
    "            verbose=1,\n",
    "        ),'''\n",
    "\n",
    "    history = model.fit(X_train,\n",
    "                        Y_train,\n",
    "                        batch_size=bs,\n",
    "                        epochs=ep,\n",
    "                        verbose=0, # verbose=0: Outputs nothing, verbose=1: Generates an output for each epoch (standard behaviour), including a progress bar.\n",
    "                        callbacks=callbacks,\n",
    "                        validation_data=(X_val, Y_val))  \n",
    "\n",
    "    t11 = t.time()\n",
    "    ######\n",
    "    ######\n",
    "    tt_elapsed = t11 - t00\n",
    "    print(\"   Time elapsed for training: %d:%02d m:sec\"\n",
    "          % (tt_elapsed / 60, (tt_elapsed / 60 - math.floor(tt_elapsed / 60)) * 60))\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    report = classification_report(Y_test.argmax(axis=1), y_pred.argmax(axis=1), zero_division=0)\n",
    "    print(report)\n",
    "\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    \n",
    "    # Access to the training loss and validation loss\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    print(f\"Loss on test dataset: {test_loss:.4f}\")\n",
    "    print(f\"Testaccuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    #######\n",
    "    #######\n",
    "    # Save neural network\n",
    "    if save_model:  # creates a '_model.keras'-file, can be loaded by keras.model.load_model()\n",
    "        \n",
    "        # Dateinamen definieren\n",
    "        filename = os.path.join(folder_reports, date + '-' + 'bs_' + str(bs) + '-ep_' + str(ep) + '-op_' + optimizer + \"_\" + version + '_classification_report.csv')\n",
    "\n",
    "        # Öffne die Datei zum Schreiben und schreibe den Bericht hinein\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(report)\n",
    "        \n",
    "        os.makedirs(folder_models, exist_ok=True)\n",
    "        model.save(os.path.join(folder_models, date + '-' + 'bs_' + str(bs) + '-ep_' + str(ep) + '-op_' + optimizer  + \"_\" + version + '_model.keras'))\n",
    "        print('Training completed')\n",
    "\n",
    "    return test_loss, test_accuracy, train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa5d76f-c381-4cb5-94b0-50a62d298cb5",
   "metadata": {},
   "source": [
    "## Loading and analysing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb99c7c-add0-419c-940c-4bf1f9b86e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X_train_std_load = np.load(os.path.join(input_path, date + \"_X_train_std_load.npy\" ))\n",
    "X_val_std_load = np.load(os.path.join(input_path, date + \"_X_val_std_load.npy\"))\n",
    "X_test_std_load = np.load(os.path.join(input_path, date + \"_X_test_std_load.npy\"))\n",
    "X_train_std_voltage = np.load(os.path.join(input_path, date + \"_X_train_std_volt.npy\"))\n",
    "X_val_std_voltage = np.load(os.path.join(input_path, date + \"_X_val_std_volt.npy\"))\n",
    "X_test_std_voltage = np.load(os.path.join(input_path, date + \"_X_test_std_volt.npy\"))\n",
    "\n",
    "\n",
    "# load output\n",
    "Y_train = np.load(input_path + date + \"_Y_train.npy\")\n",
    "Y_val = np.load(input_path + date + \"_Y_val.npy\")\n",
    "Y_test = np.load(input_path + date + \"_Y_test.npy\")\n",
    "\n",
    "num_classes = Y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d96f3c-60a0-4c24-8b5e-b9a8f167f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buil input pictures depending on the version:\n",
    "\n",
    "if version == 'geom_V1': \n",
    "    pic_dim1 = 5\n",
    "    pic_dim2 = 7\n",
    "    X_train = build_input_pic_V1(X_train_std_load, pic_dim1, pic_dim2)\n",
    "    X_test =  build_input_pic_V1(X_test_std_load, pic_dim1, pic_dim2)\n",
    "    X_val =   build_input_pic_V1(X_val_std_load, pic_dim1, pic_dim2)\n",
    "\n",
    "if version == 'geom_V2': \n",
    "    pic_dim1 = 5\n",
    "    pic_dim2 = 5\n",
    "    X_train = build_input_pic_V2(X_train_std_load, pic_dim1, pic_dim2)\n",
    "    X_test =  build_input_pic_V2(X_test_std_load, pic_dim1, pic_dim2)\n",
    "    X_val =   build_input_pic_V2(X_val_std_load, pic_dim1, pic_dim2)\n",
    "\n",
    "if version == 'geom_V3': \n",
    "    pic_dim1 = 8\n",
    "    pic_dim2 = 2\n",
    "    X_train = build_input_pic_V3(X_train_std_load, pic_dim1, pic_dim2)\n",
    "    X_test =  build_input_pic_V3(X_test_std_load, pic_dim1, pic_dim2)\n",
    "    X_val =   build_input_pic_V3(X_val_std_load, pic_dim1, pic_dim2)\n",
    "\n",
    "if version == 'geom_V4':\n",
    "    pic_dim1 = 11\n",
    "    pic_dim2 = 1\n",
    "    X_train = build_input_pic_V4(X_train_std_load, pic_dim1, pic_dim2)\n",
    "    X_test =  build_input_pic_V4(X_test_std_load, pic_dim1, pic_dim2)\n",
    "    X_val =   build_input_pic_V4(X_val_std_load, pic_dim1, pic_dim2)\n",
    "\n",
    "if version == 'geom_V5': \n",
    "    pic_dim1 = 12\n",
    "    pic_dim2 = 1\n",
    "    X_train = build_input_pic_V5(X_train_std_load, pic_dim1, pic_dim2)\n",
    "    X_test =  build_input_pic_V5(X_test_std_load, pic_dim1, pic_dim2)\n",
    "    X_val =   build_input_pic_V5(X_val_std_load, pic_dim1, pic_dim2)\n",
    "\n",
    "print('Shape of new CNN training input data: ', X_train.shape)\n",
    "print('Shape of new CNN val input data: ', X_val.shape)\n",
    "print('Shape of new CNN test input data: ', X_test.shape)\n",
    "\n",
    "# Plot first 5 samples and its corresponding classes\n",
    "plt.figure(3, figsize=(12, 9))\n",
    "\n",
    "vmin, vmax = np.min(X_train), np.max(X_train)  # Beispielwerte, an deine Daten anpassen\n",
    "\n",
    "for i in range(3):\n",
    "    img = X_train[i]\n",
    "    plt.subplot(5,10,i+1)\n",
    "    plt.title('class ' + str(Y_train.argmax(axis=1)[i]))\n",
    "    print(img)\n",
    "    plt.imshow(img.reshape(pic_dim1, pic_dim2), cmap='viridis', vmin=vmin, vmax=vmax) \n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753b6ecc-7758-435d-a9ca-83e7e2f19bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plotting the samples according to their classes to find out similarities in the data\n",
    "\n",
    "plt.figure(2, figsize=(16, 20))\n",
    "maxImg = 12\n",
    "numImg = 0\n",
    "categories = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "for n, category in enumerate(categories):\n",
    "    numImg = 0\n",
    "    for i, y in enumerate(Y_train):\n",
    "        if np.argmax(y) == category:\n",
    "            numImg += 1\n",
    "            img = X_train[i]\n",
    "            plt.subplot(len(categories),maxImg,n*maxImg+numImg)\n",
    "            # plt.subplot(maxImg,len(categories),(numImg-1)*10+(n+1))\n",
    "            plt.title('class ' + str(np.argmax(y)))\n",
    "            plt.imshow(img.reshape(pic_dim1, pic_dim2), cmap='viridis', vmin=vmin, vmax=vmax) \n",
    "            plt.axis('off')\n",
    "            if numImg>=maxImg:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb6155b-ba46-442a-83ff-ba9bdb54b844",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization\n",
    "this takes about 1 hour for 7883 simulation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6202a5-066d-4ffc-8cae-e7fcbc302589",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "t00 = t.time()\n",
    "\n",
    "# optimizer list\n",
    "op_list = ['adam', 'Nadam', 'RMSprop']\n",
    "# batch_size\n",
    "bs_list = [16, 32, 64, 128]\n",
    "# epoch_list\n",
    "ep_list = [80, 100, 200]\n",
    "\n",
    "# Defining all possible combinations of the hyperparameters\n",
    "hyperparameter_combinations = list(product(op_list, bs_list, ep_list))\n",
    "\n",
    "results = []\n",
    "# Checking all combinations\n",
    "for optimizer, bs, ep in hyperparameter_combinations:\n",
    "    test_loss, test_accuracy, train_loss, val_loss = train_model_for_build_input_pic(pic_dim1 = pic_dim1, pic_dim2 = pic_dim2, optimizer=optimizer, num_classes=num_classes, folder_models=folder_models, folder_reports=folder_reports, X_train=X_train, Y_train=Y_train, X_val=X_val, Y_val=Y_val, X_test=X_test, Y_test=Y_test, bs=bs, ep=ep, log_dir=log_dir)\n",
    "\n",
    "    results.append({\n",
    "            'optimizer': optimizer,\n",
    "            'batch_size': bs,\n",
    "            'epochs': ep,\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'test_loss': test_loss,\n",
    "            'test_accuracy': test_accuracy\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "print(df_results)\n",
    "\n",
    "# Saving dataframe to .csv\n",
    "df_results.to_csv(os.path.join(folder_reports, date + \"_\" + version + '_model_performance_summary.csv'), index=False)\n",
    "\n",
    "t11 = t.time()\n",
    "tt_elapsed = t11 - t00\n",
    "print(\"Time elapsed for hyperparameter optimization: %d:%02d m:sec\" % (tt_elapsed / 60, (tt_elapsed / 60 - math.floor(tt_elapsed / 60)) * 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084722c0-6b28-4c39-8161-121954b83d84",
   "metadata": {},
   "source": [
    "## The best combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8fcbda-b447-49e5-b757-9be7aafe1a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameter for training \n",
    "#batch size\n",
    "bs = 64\n",
    "#epochs\n",
    "ep = 200\n",
    "optimizer = 'adam'\n",
    "\n",
    "#training 'new'\n",
    "test_loss, test_accuracy, train_loss, val_loss = train_model_for_build_input_pic(pic_dim1 = pic_dim1, pic_dim2 = pic_dim2, optimizer = optimizer, num_classes = num_classes, folder_models = folder_models, folder_reports=folder_reports, X_train = X_train, Y_train = Y_train, X_val = X_val, Y_val = Y_val, X_test = X_test, Y_test = Y_test, bs = bs, ep = ep, log_dir=log_dir, save_model = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d2f29d-f5c5-4d4b-9552-8830cb93307f",
   "metadata": {},
   "source": [
    "## N-Best evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f809c51-2fa4-457a-9ef1-d73940ee3b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import trange, tqdm\n",
    "import progressbar as PB\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def pbRange(iterations):\n",
    "    '''Displays a progress bar while doing an iteration over a range.\n",
    "    Example:         for i in pbRange(42)\n",
    "    Same usage as:   for i in range(42)'''\n",
    "    return PB.progressbar(range(iterations))\n",
    "\n",
    "\n",
    "def pb(iteratable):\n",
    "    '''Displays a progress bar while doing an iteration over an iteratable.\n",
    "    Example:         for element in pb([myList])\n",
    "    Same usage as:   for elment in myList'''\n",
    "    return PB.progressbar(iteratable)\n",
    "\n",
    "def eval_Nbest(model, X_test, Y_test, N=3, verbose=0):\n",
    "    '''Evalute model's \"N-best prediction accuracy\",\n",
    "    according to the N first ranked classes (highest prediction probabilities)\n",
    "\n",
    "    Example:  Nbest = eval_Nbest(model, X_test, Y_test, 3)\n",
    "\n",
    "    Returns:  list of three elements\n",
    "      [0]  (float) calculated prediction accuracy according to N-best ranking\n",
    "      [1]  (int)   number of correct predictions according to N-best ranking\n",
    "      [2]  (list)  indices of incorrect predictions according to N-best ranking\n",
    "\n",
    "    Arguments:\n",
    "      model :   Keras model (neural network)\n",
    "      X_test:   Array of input samples for keras model\n",
    "      y_test:   associated solutions for input samples\n",
    "      N:        use first N ranked classes (descending probabilities) for evaluation\n",
    "      verbose:  0 or 1, if printing progress is desired during evaluation\n",
    "    '''\n",
    "    if N < 1:\n",
    "        N = 1\n",
    "    # predictions will contain a prediction probability value for each class\n",
    "    predictions = model.predict(X_test, verbose=verbose)\n",
    "    # check if N > number of classes\n",
    "    if N > predictions.shape[1]:\n",
    "        N = 1\n",
    "    ind = np.argpartition(predictions, -N)[:, -N:]\n",
    "    # if solution vectors are one-hot-encoded, convert to decimal values, i.e. [0, 0, 1, 0] --> \"2\"\n",
    "    if len(Y_test.shape) > 1:  # if there is a 2nd dimension in the numpy array of solution vectors\n",
    "        y_test = np.argmax(Y_test, axis=1)\n",
    "    else:\n",
    "        y_test = Y_test\n",
    "    # correct predictions: correct class (y) is among the N-best ranked probabilities of each sample\n",
    "    correct = 0     # number of correct predictions according to N-best\n",
    "    incorrect = []  # indices of incorrect predictions\n",
    "    if verbose:\n",
    "        for k, y in enumerate(pb(y_test)):\n",
    "            if np.isin(y, ind[k]):\n",
    "                correct += 1\n",
    "            else:\n",
    "                incorrect.append(k)\n",
    "    else:\n",
    "        for k, y in enumerate(y_test):\n",
    "            if np.isin(y, ind[k]):\n",
    "                correct += 1\n",
    "            else:\n",
    "                incorrect.append(k)\n",
    "    acc_n_best = correct / len(y_test)\n",
    "    return [acc_n_best, correct, incorrect]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b418435d-370a-4d1e-81e5-ffdedffc5fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model_name = '2024-03-22_13-06-27-bs_64-ep_100-op_nadam_model.keras'\n",
    "model = tf.keras.models.load_model(os.path.join('CNN_models', date, version, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8359fef9-f09f-41a8-a666-ab8d7e4f0bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test neural network using test data\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "test_acc = score[1]\n",
    "print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5547287-c661-4729-9dbf-a6d4f127315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t00 = t.time()\n",
    "Nbest_vec=[]\n",
    "for N in range(1,6):\n",
    "    print('N = ' + str(N))\n",
    "    Nbest = eval_Nbest(model, X_test, Y_test, N, verbose=0)\n",
    "    Nbest_vec.append(Nbest[0])\n",
    "    print('Test accuracy N-best:', Nbest[0])\n",
    "    #print('Correctly predicted samples:', Nbest[1])\n",
    "    #print('Indices of wrongly predicted samples:', Nbest[2])\n",
    "    print('--------------------------------------------------')\n",
    "t11 = t.time()\n",
    "tt_elapsed = t11 - t00\n",
    "print(\"Time elapsed: %.1f sec.\" %tt_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47705436-9a05-4093-8c2b-cdf12a701ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 3))\n",
    "N = range(1,6)\n",
    "bars = plt.bar(N, Nbest_vec, color='darkcyan')\n",
    "\n",
    "\n",
    "plt.xlabel('N', fontsize=14)\n",
    "plt.ylabel('Accuracy [%]', fontsize=14)\n",
    "\n",
    "# Defining y-axis\n",
    "plt.ylim(0.96, 1.005)\n",
    "\n",
    "#showing the percentage values above each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.annotate(f'{height:.2%}',\n",
    "                 xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                 xytext=(0, 3),  # 3 Punkte vertikaler Abstand\n",
    "                 textcoords=\"offset points\",\n",
    "                 ha='center', va='bottom')\n",
    "\n",
    "plt.savefig(os.path.join(folder_reports, date + '-' + 'bs_' + str(bs) + '-ep_' + str(ep) + '-op_' + optimizer + \"_\" + version + '_N-best_plot.png'), dpi=600, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24faf7f-ff1d-48ff-8d00-8af3f1144bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing N-best at one specific example\n",
    "idx = 1136\n",
    "pred = predictions[idx]\n",
    "print('associated solution:', np.argmax(Y_test[idx]))\n",
    "print('predicted solution: ', np.argmax(predictions[idx]))\n",
    "print('class: probability')\n",
    "for i, prob in enumerate(pred):\n",
    "    print(str(i) + ': %7.4f %%' %(prob*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363d4cd4-2d81-459d-ad6e-2f95ff219369",
   "metadata": {},
   "source": [
    "## For plotting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d621e23f-51f1-4177-9b7e-55c1d5406d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "import pydot, graphviz\n",
    "\n",
    "# Define model according to description\n",
    "model = Sequential([\n",
    "    Conv1D(32, 3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Conv1D(64, 3, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(264, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "# Show model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2374f9-0c09-4bc0-a5be-88f8f8509ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the path is set correctly, if necessary\n",
    "plot_model(model, to_file='model_architecture-physical_approach.png', show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
